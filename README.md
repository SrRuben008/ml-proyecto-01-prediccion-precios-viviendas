# PredicciÃ³n de precios de viviendas en California ğŸ 

## ğŸ“Œ DescripciÃ³n
Este proyecto predice el valor medio de viviendas en distintas zonas de California utilizando el dataset **California Housing** incluido en `scikit-learn`.  
El objetivo es aplicar un flujo completo de *Machine Learning*:
1. **EDA** (anÃ¡lisis exploratorio de datos).
2. **Modelo baseline** (RegresiÃ³n Lineal).
3. **Modelo avanzado** (Random Forest).
4. **OptimizaciÃ³n** (Random Forest + GridSearchCV).

---

## ğŸ“Š Dataset
- **Fuente**: [`fetch_california_housing`](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)
- **Filas**: 20640
- **Columnas**: 8 columnas (caracterÃ­sticas) + 1 target (`MedHouseVal`)
- **Unidades**:
  - `MedInc`: Media de los ingresos en decenas de miles USD.
  - `HouseAge`: aÃ±os.
  - `AveRooms`, `AveBedrms`: medias por vivienda de habitaciones y dormitorios.
  - `Population`: personas.
  - `AveOccup`: personas por hogar.
  - `Latitude`, `Longitude`: grados.
  - `MedHouseVal` (target): centenas de miles USD.

---

## ğŸ”„ Flujo de trabajo
1. **EDA** â†’ exploraciÃ³n de datos, correlaciones, hipÃ³tesis.
2. **Baseline** â†’ RegresiÃ³n Lineal para establecer referencia.
3. **Modelo avanzado** â†’ Random Forest para capturar relaciones no lineales.
4. **OptimizaciÃ³n** â†’ GridSearchCV para encontrar la mejor combinaciÃ³n de hiperparÃ¡metros (los parÃ¡metros editables antes del entrenamiento del modelo).
5. **EvaluaciÃ³n** â†’ comparaciÃ³n de mÃ©tricas y anÃ¡lisis de importancia de variables.

---

## ğŸ“ˆ Resultados

| Modelo                          | RMSE  | MAE   | RÂ²    |
|---------------------------------|-------|-------|-------|
| **RegresiÃ³n Lineal (baseline)** | 0.746 | 0.533 | 0.576 |
| **Random Forest**               | 0.503 | 0.327 | 0.807 |
| **Random Forest+GridSearchCV**  | 0.503 | 0.326 | 0.807 |

> **InterpretaciÃ³n**:  
> - El Random Forest reduce el error medio en ~22 000 USD respecto al baseline, una gran mejora.  
> - El tuning confirmÃ³ que el modelo inicial ya estaba casi optimizado.  
> - La variable mÃ¡s influyente es `MedInc`, seguida de `AveOccup` y la ubicaciÃ³n (`Latitude`, `Longitude`).

---

## ğŸ“Š Importancia de variables
![Importancias](reports/feature_importances_best_rf.png)

---

## ğŸ›  TecnologÃ­as usadas
- Python 3.12
- pandas, numpy, matplotlib, seaborn
- scikit-learn
- Jupyter Notebook

---

## ğŸ“š QuÃ© aprendÃ­
- CÃ³mo realizar un EDA estructurado.
- Por quÃ© es importante un modelo baseline antes de mejoras.
- CÃ³mo funcionan y se interpretan Random Forests.
- Uso de `GridSearchCV` para optimizaciÃ³n de hiperparÃ¡metros.
- InterpretaciÃ³n de mÃ©tricas: RMSE, MAE, RÂ².

---

## ğŸš€ PrÃ³ximos pasos
- Probar modelos de *Gradient Boosting* (`HistGradientBoostingRegressor`, XGBoost).
- AÃ±adir validaciÃ³n cruzada estratificada.
- Implementar pipeline con `ColumnTransformer` para datos mixtos.

---

## ğŸ“œ Licencia
Este proyecto estÃ¡ bajo la licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.
